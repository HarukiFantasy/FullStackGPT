{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Yes, according to the extracted text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 3099, 'total_tokens': 3126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-b6e99aa6-a114-4e07-8118-790a2ec2e993-0'\n",
      "content='He traced with his finger in the dust on the table the equation \"2+2=5.\"' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 3564, 'total_tokens': 3585, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9076bc90-bea8-4641-ac8e-0919ab2e272c-0'\n",
      "content='Julia is a character in the text who is involved in a romantic relationship with the protagonist, Winston.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 3856, 'total_tokens': 3878, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-46cc9d41-0f84-4384-b0b3-dd7810fa5a30-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\", \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100\n",
    ")      \n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/1984_chapter_three.txt\")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    chat_history = memory.load_memory_variables({})[\"chat_history\"]\n",
    "\n",
    "    # chat_history가 딕셔너리 형태일 경우, 리스트로 변환\n",
    "    if isinstance(chat_history, dict):\n",
    "        chat_history = chat_history.get(\"chat_history\", [])\n",
    "\n",
    "    # chat_history가 None일 경우 빈 리스트 반환\n",
    "    return chat_history if isinstance(chat_history, list) else []\n",
    "\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",  \n",
    "        \"\"\"\n",
    "        Use the following context of a long document to see if any of the text is relevant to answer the question.\n",
    "        Return any relevant text verbatim\n",
    "        -------\n",
    "        {context}\n",
    "        \"\"\" \n",
    "    ),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "    \n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs[\"documents\"]\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "map_chain = {\n",
    "    \"documents\": retriever, \n",
    "    \"question\": RunnablePassthrough()\n",
    "} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "        \"\"\"\n",
    "        Given the following extracted parts of a long documents and a question, create a final answer.\n",
    "        If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "        -------\n",
    "        {context}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "A = RunnableLambda(load_memory)\n",
    "chain = {\"chat_history\":A, \"context\": map_chain, \"question\": RunnablePassthrough()} | final_prompt | llm \n",
    "\n",
    "def invoke_chain(question):\n",
    "    response = chain.invoke(question)\n",
    "    memory.save_context(\n",
    "        inputs={\"input\":question}, \n",
    "        outputs={\"output\":response.content}\n",
    "    )\n",
    "    print(response)\n",
    "invoke_chain(\"Was Aaronson guilty of a crime?\")\n",
    "invoke_chain(\"What message did he write in the table?\")\n",
    "invoke_chain(\"Who is Julia?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Was Aaronson guilty of a crime?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, according to the extracted text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What message did he write in the table?', additional_kwargs={}, response_metadata={}), AIMessage(content='He traced with his finger in the dust on the table the equation \"2+2=5.\"', additional_kwargs={}, response_metadata={}), HumanMessage(content='Who is Julia?', additional_kwargs={}, response_metadata={}), AIMessage(content='Julia is a character in the text who is involved in a romantic relationship with the protagonist, Winston.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})[\"chat_history\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
