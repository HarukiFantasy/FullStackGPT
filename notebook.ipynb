{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/dvf_l6wd65n98d8w8p8_w6_w0000gn/T/ipykernel_35342/3483984907.py:11: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.1)\n",
      "/var/folders/dd/dvf_l6wd65n98d8w8p8_w6_w0000gn/T/ipykernel_35342/3483984907.py:17: LangChainDeprecationWarning: The class `UnstructuredFileLoader` was deprecated in LangChain 0.2.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-unstructured package and should be used instead. To use it run `pip install -U :class:`~langchain-unstructured` and import as `from :class:`~langchain_unstructured import UnstructuredLoader``.\n",
      "  docs = UnstructuredFileLoader(file_path).load_and_split(text_splitter=splitter)\n",
      "/var/folders/dd/dvf_l6wd65n98d8w8p8_w6_w0000gn/T/ipykernel_35342/3483984907.py:18: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = CacheBackedEmbeddings.from_bytes_store(OpenAIEmbeddings(), cache_dir)\n",
      "/var/folders/dd/dvf_l6wd65n98d8w8p8_w6_w0000gn/T/ipykernel_35342/3483984907.py:23: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Yes, according to the extracted text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 3099, 'total_tokens': 3126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-599df7f8-3f63-471e-a909-e91f385e7936-0'\n",
      "content='He traced with his finger in the dust on the table the message: 2+2=5.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 3564, 'total_tokens': 3586, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9a30f95a-0858-4dfb-8f6e-58687c759f47-0'\n",
      "content='Julia is a character in the text who is involved in a romantic relationship with the protagonist, Winston.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 3857, 'total_tokens': 3879, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-6109a8bb-d27a-4c7c-8dc6-d62cee8c82e2-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "def initialize_retriever(file_path):\n",
    "    cache_dir = LocalFileStore(\"./.cache/\")\n",
    "    splitter = CharacterTextSplitter.from_tiktoken_encoder(separator=\"\\n\", chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "    docs = UnstructuredFileLoader(file_path).load_and_split(text_splitter=splitter)\n",
    "    embeddings = CacheBackedEmbeddings.from_bytes_store(OpenAIEmbeddings(), cache_dir)\n",
    "    return FAISS.from_documents(docs, embeddings).as_retriever()\n",
    "\n",
    "retriever = initialize_retriever(\"./files/1984_chapter_three.txt\")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",  \n",
    "        \"\"\"\n",
    "        Use the following context of a long document to see if any of the text is relevant to answer the question.\n",
    "        Return any relevant text verbatim\n",
    "        -------\n",
    "        {context}\n",
    "        \"\"\" \n",
    "    ),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "    \n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs[\"documents\"]\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "map_chain = {\n",
    "    \"documents\": retriever, \n",
    "    \"question\": RunnablePassthrough()\n",
    "} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "        \"\"\"\n",
    "        Given the following extracted parts of a long documents and a question, create a final answer.\n",
    "        If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "        -------\n",
    "        {context}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "A = RunnableLambda(load_memory)\n",
    "chain = {\"chat_history\":A, \"context\": map_chain, \"question\": RunnablePassthrough()} | final_prompt | llm \n",
    "\n",
    "def invoke_chain(question):\n",
    "    response = chain.invoke(question)\n",
    "    memory.save_context(\n",
    "        inputs={\"input\":question}, \n",
    "        outputs={\"output\":response.content}\n",
    "    )\n",
    "    print(response)\n",
    "invoke_chain(\"Was Aaronson guilty of a crime?\")\n",
    "invoke_chain(\"What message did he write in the table?\")\n",
    "invoke_chain(\"Who is Julia?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Was Aaronson guilty of a crime?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, according to the extracted text, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.', additional_kwargs={}, response_metadata={}), HumanMessage(content='What message did he write in the table?', additional_kwargs={}, response_metadata={}), AIMessage(content='He traced with his finger in the dust on the table the message: 2+2=5.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Who is Julia?', additional_kwargs={}, response_metadata={}), AIMessage(content='Julia is a character in the text who is involved in a romantic relationship with the protagonist, Winston.', additional_kwargs={}, response_metadata={}), HumanMessage(content='what was my first question?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Your first question was about Aaronson's guilt in a crime.\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})[\"chat_history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Your first question was about Aaronson's guilt in a crime.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 3558, 'total_tokens': 3572, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-1d321c5a-a9fd-4680-aadc-6fa791796a02-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"what was my first question?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
