import os
import requests
import xml.etree.ElementTree as ET
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
from langchain.vectorstores.faiss import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
import streamlit as st
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from langchain_community.document_loaders import AsyncChromiumLoader

# ğŸ¯ ëŒ€í™” ë©”ì‹œì§€ ìƒíƒœ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = []

def save_message(message, role):
    st.session_state["messages"].append({"message": message, "role": role})

def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)

def paint_history():
    for msg in st.session_state["messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["message"])

def get_chat_history():
    return "\n".join(f"{msg['role']}: {msg['message']}" for msg in st.session_state["messages"])

llm = ChatOpenAI(temperature=0.1)

# ğŸ¯ í”„ë¡¬í”„íŠ¸ ì •ì˜
answers_prompt = ChatPromptTemplate.from_template(
    """
    Chat History:
    {chat_history}

    Website Content:
    {context}

    Using the above information, answer the user's question.
    Then, give a score to the answer between 0 and 5.

    Your turn!
    Question: {question}
    """
)

def get_answers(inputs):
    docs = inputs["docs"]
    question = inputs["question"]
    chat_history = get_chat_history()
    answers_chain = answers_prompt | llm
    return {
        "question": question,
        "answers": [
            { 
                "answer": answers_chain.invoke(
                    {"question": question, "context": doc.page_content, "chat_history": chat_history}
                ).content,
                "source": doc.metadata["source"],
            } for doc in docs
        ],
    }

choose_prompt = ChatPromptTemplate.from_messages([
    ("system", "Use ONLY the following answers to respond."),
    ("human", "{question}"),
])

def choose_answer(inputs):
    answers = inputs["answers"]
    question = inputs["question"]
    choose_chain = choose_prompt | llm
    condensed = "\n\n".join(f"{answer['answer']}\nSource:{answer['source']}" for answer in answers)
    return choose_chain.invoke({"question": question, "answers": condensed})

# ğŸ¯ Seleniumì„ ì‚¬ìš©í•œ ë™ì  HTML ë¡œë”©
def fetch_dynamic_content(url):
    """ JavaScriptê°€ ë Œë”ë§ëœ í›„ì˜ HTMLì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ """
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    
    driver.get(url)
    driver.implicitly_wait(7)  # ğŸš€ JS ì‹¤í–‰ í›„ ë¡œë”© ì‹œê°„ ì¦ê°€
    html = driver.page_source
    driver.quit()
    
    return html

# ğŸ¯ í˜ì´ì§€ ë³¸ë¬¸ ì¶”ì¶œ (ìë™ íƒœê·¸ íƒìƒ‰)
def parse_page(soup):
    """ ë³¸ë¬¸ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ """
    content_tags = ["main", "article", "section", "div"]
    for tag in content_tags:
        content = soup.find(tag)
        if content:
            return content.get_text().strip()

    return soup.get_text().strip()

# ğŸ¯ ì‚¬ì´íŠ¸ë§µì—ì„œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ URLë§Œ ì¶”ì¶œ
def parse_urls(sitemap_url, keyword):
    if sitemap_url:
        try:
            # ì‚¬ì´íŠ¸ë§µ URLì—ì„œ XML ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
            response = requests.get(sitemap_url)
            response.raise_for_status()  # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬

            # XML íŒŒì‹±
            root = ET.fromstring(response.content)
            # ê¸°ë³¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì§€ì •
            ns = {"ns": "http://www.sitemaps.org/schemas/sitemap/0.9"}
            urls = []

            # ëª¨ë“  <url> ìš”ì†Œ ìˆœíšŒí•˜ë©° <loc> íƒœê·¸ì˜ í…ìŠ¤íŠ¸(ì‹¤ì œ URL) ì¶”ì¶œ
            for url_elem in root.findall("ns:url", ns):
                loc = url_elem.find("ns:loc", ns)
                if loc is not None:
                    url_text = loc.text
                    # í‚¤ì›Œë“œê°€ ì…ë ¥ëœ ê²½ìš°, URLì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if keyword:
                        if keyword.lower() in url_text.lower():
                            urls.append(url_text)
                    else:
                        urls.append(url_text)

            return urls  # âœ… URL ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

        except Exception as e:
            st.error(f"Error fetching/parsing sitemap: {e}")
            return []  # âœ… ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

# ğŸ¯ FAISS ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•˜ì§€ ì•Šê³  ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ìƒì„±
@st.cache_data(show_spinner="Loading website...")
def load_website(sitemap_url, keyword=None):
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000,
        chunk_overlap=200,
    )

    # âœ… ë¦¬í„´ê°’ì„ ë°›ì•„ì„œ Streamlit UIì— í‘œì‹œ
    filtered_urls = parse_urls(sitemap_url, keyword)

    # âœ… ë°˜í™˜ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ì—¬ ì¶œë ¥
    if filtered_urls:
        st.write("Filtered URLs:" if keyword else "Extracted URLs:")
        st.write(filtered_urls)
        for page_url in filtered_urls: 
            raw_html = fetch_dynamic_content(page_url)
            soup = BeautifulSoup(raw_html, "html.parser")
            st.write(parse_page(soup))
    else:
        st.write("No URLs found with the given keyword." if keyword else "No URLs found.")
        

    loader = AsyncChromiumLoader(filtered_urls)
    loader.requests_per_second = 2
    docs = loader.load()
    docs = splitter.split_documents(docs)
    vector_store = FAISS.from_documents(docs, OpenAIEmbeddings())
    print(vector_store.as_retriever())
    return vector_store.as_retriever()


# ğŸ¯ Streamlit UI ì„¤ì •
st.set_page_config(page_title="SiteGPT", page_icon="ğŸ–¥ï¸")

st.markdown("""
# SiteGPT
Ask questions about the content of a website.
Enter the Sitemap URL in the sidebar to begin.
""")

with st.sidebar:
    sitemap_url = st.text_input("Enter Sitemap URL", placeholder="https://example.com/sitemap.xml")
    keyword = st.text_input("Input keyword (optional)", placeholder="Keyword")
    load_button = st.button("Load Website")

# ğŸ¯ ì›¹ì‚¬ì´íŠ¸ ë¡œë“œ ë° ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬
if sitemap_url and load_button:
    if ".xml" not in sitemap_url:
        st.error("Please enter a valid Sitemap URL.")
    else:
        retriever = load_website(sitemap_url, keyword)

        if retriever:
            paint_history()
            user_input = st.chat_input("Ask a question about the website.")

            if user_input:
                send_message(user_input, "human")
                chain = ({"docs": retriever, "question": RunnablePassthrough()} | RunnableLambda(get_answers) | RunnableLambda(choose_answer))
                result = chain.invoke(user_input)
                answer = result.content.replace("$", "\$")
                send_message(answer, "ai")
